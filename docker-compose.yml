services:

# Database 
  database:
    container_name: database
    build:
      context: ./database
      dockerfile: Dockerfile
    env_file:
      - ./database/.env
    volumes:
      - database:/data/db
    restart: unless-stopped

# Adminer UI
  adminer:
    container_name: adminer
    image: adminer
    ports:
      - "8081:8080"
    restart: unless-stopped
    depends_on:
      database:
        condition: service_healthy

# Backend FastAPI
  backend:
    container_name: backend
    build:
      context: ./backend
      dockerfile: Dockerfile
    env_file:
      - ./backend/.env
    ports:
      - "8000:8000"
    depends_on:
      database:
        condition: service_healthy
      rabbitmq:
        condition: service_started
    volumes:
      - ./backend/data:/app/backend/data
    restart: unless-stopped

 # RabbitMQ (con UI de administraci√≥n)
  rabbitmq:
    container_name: rabbitmq
    image: rabbitmq:3-management
    ports:
      - "5672:5672"   
      - "15672:15672" 
    restart: unless-stopped

  # Ollama (servidor de LLM)
  #ollama:
  #  container_name: ollama
  #  image: ollama/ollama:latest
  #  ports:
  #    - "11434:11434" 
  #  volumes:
  #    - ollama_data:/root/.ollama
  #  restart: unless-stopped

  # Worker: preprocesamiento a Markdown
  worker-preprocess:
    container_name: worker-preprocess
    build:
      context: ./pipelines/preprocess
      dockerfile: Dockerfile
    volumes:
      - ./backend/data:/app/data   
    depends_on:
      - rabbitmq
      #- ollama
    restart: unless-stopped

# Volumes
volumes:
  database:
    driver: local
  #ollama_data:
  #  driver: local